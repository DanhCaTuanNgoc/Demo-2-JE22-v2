server.port=1234

# Spring AI + OpenRouter Configuration
# API Key (required - get from https://openrouter.ai/keys)
spring.ai.openai.api-key=${OPENROUTER_API_KEY:}

# Base URL for OpenRouter API (OpenAI-compatible)
spring.ai.openai.base-url=${OPENROUTER_BASE_URL:https://openrouter.ai/api}

# Chat Model Configuration
spring.ai.openai.chat.options.model=${OPENROUTER_MODEL:meta-llama/llama-3.1-70b-instruct}
spring.ai.openai.chat.options.temperature=${OPENROUTER_TEMPERATURE:0.7}
spring.ai.openai.chat.options.max-tokens=${OPENROUTER_MAX_TOKENS:1000}

# Disable ALL Spring AI OpenAI auto-config (we only use chat manually + Hugging Face for embedding)
spring.ai.openai.embedding.enabled=false
spring.ai.openai.image.enabled=false
spring.ai.openai.audio.enabled=false
spring.ai.openai.audio.transcription.enabled=false
spring.ai.openai.audio.speech.enabled=false
spring.ai.openai.moderation.enabled=false

# Hugging Face Embedding Configuration
huggingface.api.key=${HUGGINGFACE_API_KEY:}
huggingface.embedding.model=${HUGGINGFACE_EMBEDDING_MODEL:sentence-transformers/all-MiniLM-L6-v2}
huggingface.api.url=${HUGGINGFACE_API_URL:https://api-inference.huggingface.co/pipeline/feature-extraction}

# Application name for OpenRouter headers
spring.application.name=demo-rag

# RAG
rag.chunk.size=${RAG_CHUNK_SIZE:1000}
rag.chunk.overlap=${RAG_CHUNK_OVERLAP:200}
rag.top.k=${RAG_TOP_K:4}
rag.threshold=${RAG_THRESHOLD:0.35}

# System Prompt for AI
ai.system.prompt=${AI_SYSTEM_PROMPT:You are a helpful AI assistant specialized in analyzing documents. \
You provide accurate, concise answers based on the provided context. \
Always respond in Vietnamese unless asked otherwise. \
If you don't know the answer based on the context, say so clearly. \
Be professional, clear, and helpful in your responses.}

management.endpoints.web.exposure.include=health,info

spring.servlet.multipart.max-file-size=${UPLOAD_MAX_FILE:64MB}
spring.servlet.multipart.max-request-size=${UPLOAD_MAX_REQUEST:64MB}